

# 数据挖掘大作业二：关联规则挖掘


## 1.数据源

选择数据集2即building_permits数据集进行分析。

### 1.数据预处理 转换成适合数据挖掘的形式

经过分析，从原有的数据中选出7列，分别是Current Status、Structural Notification、Number of Proposed Stories、Fire Only Permit、TIDF Compliance、Proposed Construction Type、Site Permit。其中除Number of Proposed Stories外都是标称属性的数据。

使用R语言

```
data_bp = select(data_bp,Current.Status,Structural.Notification,Number.of.Proposed.Stories,Fire.Only.Permit,TIDF.Compliance,Proposed.Construction.Type,Site.Permit)

```
将需要使用的数据取出

再分别对7列数据进行处理

```
#Structural Notification类型中，使用“given”代替数据Y，使用“notGiven”代替空白。
data_bp$Structural.Notification <- ifelse(data_bp$Structural.Notification == "Y", "given", "notGiven")

#Fire Only Permit类型中，使用“Fpermit”代替数据Y，使用“notFPermit”代替空白。
data_bp$Fire.Only.Permit <- ifelse(data_bp$Fire.Only.Permit == "Y", "Fpermit", "notFPermit")

#Site Permit类型中，使用“Spermit”代替数据Y，使用“notSPermit”代替空白。
data_bp$Site.Permit <- ifelse(data_bp$Site.Permit == "Y", "Spermit", "notSPermit")

#TIDF Compliance类型中，使用“yes”代替数据Y，使用“no”代替空白。
data_bp$TIDF.Compliance <- ifelse(data_bp$TIDF.Compliance == "Y", "yes", "no")

#Proposed Construction Type类型中，使用“first”代替数据1，使用“second”代替数据2，使用“third”代替数据3，使用“fourth”代替数据4，使用“fifth”代替数据5。
data_bp$Proposed.Construction.Type[is.na(data_bp$Proposed.Construction.Type)] <- 'noType'
data_bp[data_bp$Proposed.Construction.Type == '1','Proposed.Construction.Type'] = 'first'
data_bp[data_bp$Proposed.Construction.Type == '2','Proposed.Construction.Type'] = 'second'
data_bp[data_bp$Proposed.Construction.Type == '3','Proposed.Construction.Type'] = 'third'
data_bp[data_bp$Proposed.Construction.Type == '4','Proposed.Construction.Type'] = 'fourth'
data_bp[data_bp$Proposed.Construction.Type == '5','Proposed.Construction.Type'] = 'fifth'

#Number of Proposed Stories类型中，小于20的为“few”，大于20小于40的为“medium”，大于40的为“large”
data_bp$Number.of.Proposed.Stories[is.na(data_bp$Number.of.Proposed.Stories)] <- -1
data_bp[data_bp$Number.of.Proposed.Stories == -1,'Number.of.Proposed.Stories'] = 'unknown'
data_bp[data_bp$Number.of.Proposed.Stories >=  0.0 & data_bp$Number.of.Proposed.Stories< 20.0,'Number.of.Proposed.Stories'] = 'few'
data_bp[data_bp$Number.of.Proposed.Stories >= 20.0 & data_bp$Number.of.Proposed.Stories< 40.0 ,'Number.of.Proposed.Stories'] = 'medium'
data_bp[data_bp$Number.of.Proposed.Stories >= 40.0,'Number.of.Proposed.Stories'] = 'large'
```
然后存为新的.csv文件备用。处理完后的部分数据见下图：

![](https://github.com/zyh0904/dm2-report/blob/master/img/data_dp.PNG?raw=true)


### 2.找出频繁项集

使用如下代码，找出频繁项集
```
#加载数据
dataBP = read.transactions("DATA_BP.csv",format="basket",sep=",",rm.duplicates=TRUE)
#得到频繁项集并保存
frequentsets=eclat(dataBP,parameter=list(support=0.05,maxlen=7))
write(frequentsets, file="frequentsets.csv", sep=",", quote=TRUE, row.names=FALSE) 
#查看频繁项集
inspect(frequentsets)
inspect(sort(frequentsets)[1:10]) 
```
部分结果如下图：

![](https://github.com/zyh0904/dm2-report/blob/master/img/%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E7%BB%93%E6%9E%9C.PNG?raw=true)


### 3.导出关联规则，计算其支持度和置信度

![](https://github.com/zyh0904/dm2-report/blob/master/img/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%8F%8A%E7%BD%AE%E4%BF%A1%E5%BA%A6.png?raw=true)
